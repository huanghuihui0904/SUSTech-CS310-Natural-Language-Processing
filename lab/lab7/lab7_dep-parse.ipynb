{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Lab 7: Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dep_utils import conll_reader, DependencyTree\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dependency-Annotated Data\n",
    "\n",
    "The data used in this lab are listed as follows:\n",
    "- data/train.conll - Training data.  ~40k sentences\n",
    "- data/dev.conll - Development data.  ~1.7k sentences. Used for observing loss and accuracy during training, and for tuning hyperparameters.\n",
    "- data/test.conll - Test data.  ~2.4k sentences. Used for evaluating the final model.\n",
    "\n",
    "The data are from a split of the WSJ part of the Penn Treebank.\n",
    "\n",
    "The data are in CoNLL-X  format (CoNLL: Conference on Computational Natural Language learning) Each sentences corresponds to a number of lines, one per word. Sentences are separated with a blank line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train.conll:\n",
      "39832 trees read.\n",
      "In dev.conll:\n",
      "1700 trees read.\n",
      "In test.conll:\n",
      "2416 trees read.\n"
     ]
    }
   ],
   "source": [
    "print('In train.conll:')\n",
    "with open('data/train.conll') as f:\n",
    "    train_trees = list(conll_reader(f))\n",
    "print(f'{len(train_trees)} trees read.')\n",
    "\n",
    "print('In dev.conll:')\n",
    "with open('data/dev.conll') as f:\n",
    "    dev_trees = list(conll_reader(f))\n",
    "print(f'{len(dev_trees)} trees read.')\n",
    "\n",
    "print('In test.conll:')\n",
    "with open('data/test.conll') as f:\n",
    "    test_trees = list(conll_reader(f))\n",
    "print(f'{len(test_trees)} trees read.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some processed sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThe\t_\t_\tDT\t_\t2\tdet\t_\t_\n",
      "2\tbill\t_\t_\tNN\t_\t3\tnsubj\t_\t_\n",
      "3\tintends\t_\t_\tVBZ\t_\t0\troot\t_\t_\n",
      "4\tto\t_\t_\tTO\t_\t5\tmark\t_\t_\n",
      "5\trestrict\t_\t_\tVB\t_\t3\txcomp\t_\t_\n",
      "6\tthe\t_\t_\tDT\t_\t7\tdet\t_\t_\n",
      "7\tRTC\t_\t_\tNNP\t_\t5\tdobj\t_\t_\n",
      "8\tto\t_\t_\tTO\t_\t10\tcase\t_\t_\n",
      "9\tTreasury\t_\t_\tNNP\t_\t10\tcompound\t_\t_\n",
      "10\tborrowings\t_\t_\tNNS\t_\t5\tnmod\t_\t_\n",
      "11\tonly\t_\t_\tRB\t_\t10\tadvmod\t_\t_\n",
      "12\t,\t_\t_\t,\t_\t3\tpunct\t_\t_\n",
      "13\tunless\t_\t_\tIN\t_\t16\tmark\t_\t_\n",
      "14\tthe\t_\t_\tDT\t_\t15\tdet\t_\t_\n",
      "15\tagency\t_\t_\tNN\t_\t16\tnsubj\t_\t_\n",
      "16\treceives\t_\t_\tVBZ\t_\t3\tadvcl\t_\t_\n",
      "17\tspecific\t_\t_\tJJ\t_\t19\tamod\t_\t_\n",
      "18\tcongressional\t_\t_\tJJ\t_\t19\tamod\t_\t_\n",
      "19\tauthorization\t_\t_\tNN\t_\t16\tdobj\t_\t_\n",
      "20\t.\t_\t_\t.\t_\t3\tpunct\t_\t_\n"
     ]
    }
   ],
   "source": [
    "tree = dev_trees[2]\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell prints the 3rd sentence in dev.conll, which consists of 20 words (including punctuations) in 20 lines.\n",
    "\n",
    "Each line contains fields, seperated by a single tab symbol, as follows:\n",
    "\n",
    "- Word ID: Word index, integer starting from 1 for each new sentence.\n",
    "- Word form: The word itself.\n",
    "- Lemma: Unused (represented as an underscore \"_\").\n",
    "- Universal POS: Unused (represented as an underscore \"_\").\n",
    "- POS: Part of speech tag.\n",
    "- Features: Unused (represented as an underscore \"_\").\n",
    "- Word ID of the **head** of the current word.\n",
    "- Dependency relation: The dependency relation between the head and the current word.\n",
    "- deps: Unused (represented as an underscore \"_\").\n",
    "- misc: Unused (represented as an underscore \"_\").\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1. Statistics of Dependency Relations\n",
    "\n",
    "Study the code of `DependencyTree` and `DependencyEdge` classes in  `utils.py`, and then count the number of unique dependency relations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number fo unique relations: 39\n",
      "{'dep', 'expl', 'nmod', 'mwe', 'discourse', 'parataxis', 'cc:preconj', 'nsubjpass', 'advcl', 'root', 'xcomp', 'appos', 'case', 'det', 'punct', 'aux', 'cop', 'dobj', 'compound', 'mark', 'ccomp', 'cc', 'auxpass', 'det:predet', 'conj', 'neg', 'nsubj', 'amod', 'csubj', 'iobj', 'nmod:npmod', 'nummod', 'advmod', 'nmod:tmod', 'compound:prt', 'acl', 'nmod:poss', 'acl:relcl', 'csubjpass'}\n",
      "Number of occurrences of ROOT: 43948\n"
     ]
    }
   ],
   "source": [
    "rel_counter = Counter()\n",
    "\n",
    "### START YOUR CODE ###\n",
    "def count_relations_in_trees(trees):\n",
    "    count=0\n",
    "    for tree in trees:\n",
    "        for deprel in tree.deprels.values():\n",
    "            rel_counter[deprel.deprel] += 1\n",
    "count_relations_in_trees(train_trees)\n",
    "count_relations_in_trees(dev_trees)\n",
    "count_relations_in_trees(test_trees)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "# Test results\n",
    "print('Total number fo unique relations:', len(rel_counter))\n",
    "print(set(rel_counter.keys()))\n",
    "print('Number of occurrences of ROOT:', rel_counter['root'])\n",
    "\n",
    "# You should expect to see the following output:\n",
    "# Total number fo unique relations: 39\n",
    "# {'nummod', 'root', 'nmod:tmod', 'nmod', 'punct', 'expl', 'auxpass', 'neg', 'nsubjpass', 'appos' ...\n",
    "# Number of occurrences of ROOT: 43948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Generate Training Data\n",
    "\n",
    "Study the code of the following `State` class\n",
    "\n",
    "**Note**:\n",
    "- The `State` class consists of `stack`, `buffer`, and `deps` as its members\n",
    "- `stack` and `buffer` are lists of word IDs (integers)\n",
    "  - The top of stack is `stack[-1]`\n",
    "  - The front of buffer is `buffer[-1]`\n",
    "- `deps` represents the currently found dependencies\n",
    "  - It is a list of `(parent, child, relation)` triples, where `parent` and `child` are integer IDs and `relation` is a string (the dependency label).\n",
    "- The `shift` methods moves the front of the buffer to the top of the stack\n",
    "- The `left_arc` method adds a head-dependent relation between the top two words on stack: $s_1 \\rightarrow s_2$. Here $s_1$ is `stack[-1]`.\n",
    "- The `right_arc` method adds a head-dependent relation between the top two words on stack: $s_2 \\rightarrow s_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self, sentence=[]):\n",
    "        self.stack = []\n",
    "        self.buffer = []\n",
    "        if sentence:\n",
    "            self.buffer = list(reversed(sentence))\n",
    "        self.deps = set()\n",
    "\n",
    "    def shift(self):\n",
    "        ### START YOUR CODE ###\n",
    "        if self.buffer:\n",
    "            front_of_buffer=self.buffer[-1]\n",
    "            self.buffer.pop()\n",
    "            self.stack.append(front_of_buffer)\n",
    "\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def left_arc(self, label: str):\n",
    "        assert len(self.stack) >= 2\n",
    "        ### START YOUR CODE ###\n",
    "\n",
    "        s1=self.stack[-1]\n",
    "        s2 = self.stack[-2]  \n",
    "        \n",
    "\n",
    "        self.stack.pop(-2)\n",
    "\n",
    "        self.deps.add((s1, s2, label))\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def right_arc(self, label: str):\n",
    "        assert len(self.stack) >= 2\n",
    "        ### START YOUR CODE ###\n",
    "        s1=self.stack[-1]\n",
    "        s2 = self.stack[-2] \n",
    "        \n",
    "        self.stack.pop()\n",
    "\n",
    "        self.deps.add((s2, s1, label))\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"({},{},{})\".format(self.stack, self.buffer, self.deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 shifts: ([0, 1],[4, 3, 2],set())\n",
      "before right-arc: ([0, 1, 2],[4, 3],set())\n",
      "after right-arc: ([0, 1],[4, 3],{(1, 2, 'label1')})\n",
      "before left-arc: ([0, 1, 3, 4],[],{(1, 2, 'label1')})\n",
      "after left-arc: ([0, 1, 4],[],{(4, 3, 'label2'), (1, 2, 'label1')})\n"
     ]
    }
   ],
   "source": [
    "# Test results\n",
    "state = State([0,1,2,3,4])\n",
    "state.shift()\n",
    "state.shift()\n",
    "print('after 2 shifts:', state)\n",
    "\n",
    "state.shift()\n",
    "print('before right-arc:', state)\n",
    "state.right_arc('label1')\n",
    "print('after right-arc:', state)\n",
    "\n",
    "state.shift()\n",
    "state.shift()\n",
    "print('before left-arc:', state)\n",
    "state.left_arc('label2')\n",
    "print('after left-arc:', state)\n",
    "\n",
    "\n",
    "# You should expect to see the following output:\n",
    "# after 2 shifts: ([0, 1],[4, 3, 2],set())\n",
    "# before right-arc: ([0, 1, 2],[4, 3],set())\n",
    "# after right-arc: ([0, 1],[4, 3],{(1, 2, 'label1')})\n",
    "# before left-arc: ([0, 1, 3, 4],[],{(1, 2, 'label1')})\n",
    "# after left-arc: ([0, 1, 4],[],{(1, 2, 'label1'), (4, 3, 'label2')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the folliwing `get_training_instances` function, so that it can generate the training data instances from a given dependency tree.\n",
    "\n",
    "The return type of this function is a list of two-elements tuples:\n",
    "- Tuple[0] is a `State` object, deepcopied from the initial state\n",
    "- Tuple[1] is a a tuple of `(action, relation)` where `action` is from {\"shift\", \"left_arc\", \"right_arc\"} and `relation` is the specific dependency relation.\n",
    "\n",
    "The transition action is decided in the `if ... elif ... else` block, which corresponds to the following three cases:\n",
    "- If $s_1 \\rightarrow s_2$ exists in `deprels`, then `left_arc` is performed.\n",
    "- If $s_2 \\rightarrow s_1$ exists in `deprels`, **AND** all rules with $s_1$ as the head have already been assigned, then `right_arc` is performed.\n",
    "- Perform `shift` otherwise.\n",
    "\n",
    "Note that we use the dictionary `childcount` to count the number of relations with each word as the head. Each time after a `left_arc` or `right_arc` is performed, the corresponding count is decreased by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootDummy(object):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.id = 0\n",
    "        self.deprel = None\n",
    "    def __repr__(self):\n",
    "        return \"<ROOT>\"\n",
    "\n",
    "\n",
    "def get_training_instances(dep_tree) -> List[Tuple[State, Tuple[str, str]]]:\n",
    "    deprels = dep_tree.deprels\n",
    "\n",
    "    word_ids = list(deprels.keys())\n",
    "\n",
    "    print(deprels.values()[0].)\n",
    "\n",
    "    state = State(word_ids)\n",
    "    state.stack.append(0) # ROOT\n",
    "\n",
    "    childcount = defaultdict(int)\n",
    "    for _, rel in deprels.items():\n",
    "        childcount[rel.head] += 1\n",
    "\n",
    "    seq = []\n",
    "\n",
    "\n",
    "    dep_relation=[]\n",
    "    for i in range(1,len(deprels)+1):\n",
    "        dep_relation.append((deprels[i].head,i))\n",
    "    \n",
    "\n",
    "    while len(state.buffer) > 0 or len(state.stack) > 1:\n",
    "    \n",
    "\n",
    "        if state.stack[-1] == 0:\n",
    "            seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "            state.shift()\n",
    "            continue\n",
    "        \n",
    "        stack_top1 = deprels[state.stack[-1]]\n",
    "        if state.stack[-2] == 0:\n",
    "            stack_top2 = RootDummy()\n",
    "        else:\n",
    "            stack_top2 = deprels[state.stack[-2]]\n",
    "\n",
    "        ### START YOUR CODE ###\n",
    "\n",
    "        if (int(state.stack[-1]), int(state.stack[-2])) in dep_relation:\n",
    "            relation = stack_top2.deprel\n",
    "            \n",
    "            action = \"left_arc\"\n",
    "            \n",
    "            seq.append((copy.deepcopy(state), (action, relation)))\n",
    "            childcount[state.stack[-1]] -= 1 \n",
    "            state.left_arc(relation)\n",
    "        elif (int(state.stack[-2]), int(state.stack[-1])) in dep_relation and childcount[state.stack[-1]] == 0:\n",
    "            relation = stack_top1.deprel\n",
    "            \n",
    "            action = \"right_arc\"\n",
    "            \n",
    "            seq.append((copy.deepcopy(state), (action, relation)))\n",
    "            childcount[state.stack[-2]] -= 1\n",
    "            state.right_arc(relation)\n",
    "        else:\n",
    "            \n",
    "            seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "            state.shift()\n",
    "            \n",
    "        ### END YOUR CODE ###\n",
    "    \n",
    "    seq.append((copy.deepcopy(state), (\"done\", None)))\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a toy tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tBook\t_\t_\tVERB\t_\t0\troot\t_\t_\n",
      "2\tthe\t_\t_\tDET\t_\t3\tdet\t_\t_\n",
      "3\tflight\t_\t_\tNOUN\t_\t1\tobj\t_\t_\n",
      "4\tthrough\t_\t_\tADP\t_\t5\tcase\t_\t_\n",
      "5\tHouston\t_\t_\tPROPN\t_\t3\tnmod\t_\t_\n"
     ]
    }
   ],
   "source": [
    "toy_tree_str = \"\"\"\n",
    "1\\tBook\\t_\\t_\\tVERB\\t_\\t0\\troot\\t_\\t_\n",
    "2\\tthe\\t_\\t_\\tDET\\t_\\t3\\tdet\\t_\\t_\n",
    "3\\tflight\\t_\\t_\\tNOUN\\t_\\t1\\tobj\\t_\\t_\n",
    "4\\tthrough\\t_\\t_\\tADP\\t_\\t5\\tcase\\t_\\t_\n",
    "5\\tHouston\\t_\\t_\\tPROPN\\t_\\t3\\tnmod\\t_\\t_\n",
    "\"\"\"\n",
    "toy_tree = DependencyTree.from_string(toy_tree_str)\n",
    "print(toy_tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with some sentence in dev.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data instances: 41\n",
      "[(([0],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1],set()),\n",
      "  ('shift', None)),\n",
      " (([0, 1],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2],set()),\n",
      "  ('shift', None)),\n",
      " (([0, 1, 2],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3],set()),\n",
      "  ('left_arc', 'det'))]\n"
     ]
    }
   ],
   "source": [
    "# Test results\n",
    "data = get_training_instances(dev_trees[2])\n",
    "print('Number of data instances:', len(data))\n",
    "pprint(data[:3])\n",
    "\n",
    "# You should expect to see the following output:\n",
    "# Number of data instances: 41\n",
    "# [(([0],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1],set()),\n",
    "#   ('shift', None)),\n",
    "#  (([0, 1],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2],set()),\n",
    "#   ('shift', None)),\n",
    "#  (([0, 1, 2],[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3],set()),\n",
    "#   ('left_arc', 'det'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note**:\n",
    "- The last element in the returned list of instances is a pseudo instance with the label `\"done\"`. This is for demenstration purpose, and should not be used for training.\n",
    "- For actual training step, you need to post-process the data to convert each relation tuple to an integer index. \n",
    "- We have 39 unique dependency relations in the data, including `ROOT`. Considering `ROOT` only appears as the head in a `right_arc` action, we have $(39-1)\\times 2 + 1 = 77$ possible actions in total.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for converting the generated data instances into a a more *model-friendly* format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def process(dep_trees: List[DependencyTree], word_vocab: dict, pos_vocab: dict, action_vocab) -> torch.Tensor:\n",
    "    tensor_data = []\n",
    "    for tree in dep_trees:\n",
    "        instances = get_training_instances(tree)\n",
    "        for state, action in instances:\n",
    "            # TODO\n",
    "            # convert to torch tensor and append to tensor_data\n",
    "            pass\n",
    "\n",
    "    return torch.stack(tensor_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
