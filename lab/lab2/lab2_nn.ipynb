{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS310 Natural Language Processing\n",
    "# Lab 2: Neural Text Classification\n",
    "\n",
    "This tutorial is adopted from the official PyTorch tutorial: *Text classification with the torchtext library*\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html#text-classification-with-the-torchtext-library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install torchtext\n",
    "\n",
    "Url: https://pypi.org/project/torchtext/\n",
    "```bash\n",
    "conda install -c pytorch torchtext\n",
    "```\n",
    "\n",
    "You may or may not need to manually install the following packages:\n",
    "    \n",
    "```bash\n",
    "pip install chardet\n",
    "pip install -U portalocker>=2.0.0\n",
    "```\n",
    "\n",
    "or with conda\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge 'portalocker>=2.0.0'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import SST2 # SST2 is the sentiment analysis dataset, binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hide new secretions from the parental units', 0)\n",
      "('contains no wit , only labored gags', 0)\n",
      "('that loves its characters and communicates something rather beautiful about human nature', 1)\n",
      "('remains utterly satisfied to remain the same throughout', 0)\n",
      "('on the worst revenge-of-the-nerds clichés the filmmakers could dredge up', 0)\n",
      "(\"that 's far too tragic to merit such superficial treatment\", 0)\n",
      "('demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop .', 1)\n",
      "('of saucy', 1)\n"
     ]
    }
   ],
   "source": [
    "# Check the raw data\n",
    "train_iter = iter(SST2(split='train'))\n",
    "\n",
    "count = 0\n",
    "for item in train_iter:\n",
    "    print(item)\n",
    "    count += 1\n",
    "    if count > 7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hide', 'new', 'secretions', 'from', 'the', 'parental', 'units']\n",
      "['contains', 'no', 'wit', ',', 'only', 'labored', 'gags']\n",
      "['that', 'loves', 'its', 'characters', 'and', 'communicates', 'something', 'rather', 'beautiful', 'about', 'human', 'nature']\n",
      "['remains', 'utterly', 'satisfied', 'to', 'remain', 'the', 'same', 'throughout']\n",
      "['on', 'the', 'worst', 'revenge-of-the-nerds', 'clichés', 'the', 'filmmakers', 'could', 'dredge', 'up']\n",
      "['that', \"'\", 's', 'far', 'too', 'tragic', 'to', 'merit', 'such', 'superficial', 'treatment']\n",
      "['demonstrates', 'that', 'the', 'director', 'of', 'such', 'hollywood', 'blockbusters', 'as', 'patriot', 'games', 'can', 'still', 'turn', 'out', 'a', 'small', ',', 'personal', 'film', 'with', 'an', 'emotional', 'wallop', '.']\n",
      "['of', 'saucy']\n"
     ]
    }
   ],
   "source": [
    "# Check the output of yield_tokens()\n",
    "count = 0\n",
    "for tokens in yield_tokens(iter(SST2(split='train'))): # Use a new iterator\n",
    "    print(tokens)\n",
    "    count += 1\n",
    "    if count > 7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(iter(SST2(split='train'))), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224, 10, 16, 1567]\n",
      "[4579, 92, 13266, 38, 1, 7742, 10000]\n",
      "[5, 7100]\n",
      "[224, 10, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check the vocab\n",
    "print(vocab(['here', 'is', 'an', 'example']))\n",
    "print(vocab(['hide', 'new', 'secretions', 'from', 'the', 'parental', 'units']))\n",
    "print(vocab(['of', 'saucy']))\n",
    "\n",
    "# What about unknown words, i.e., out-of-vocabulary (OOV) words?\n",
    "print(vocab(['here', 'is', 'a', '@#$@!#$%']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224, 10, 1, 16, 1567]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Test text_pipeline()\n",
    "tokens = text_pipeline('here is the an example')\n",
    "print(tokens)\n",
    "\n",
    "# Test label_pipeline()\n",
    "lbl = label_pipeline('1')\n",
    "print(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batch\n",
    "\n",
    "Define the `Collate_batch` function, which will be used to process the \"raw\" data batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, token_ids_list, offsets = [], [], [0]\n",
    "    for _text, _label in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        token_ids = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        token_ids_list.append(token_ids)\n",
    "        offsets.append(token_ids.size(0))\n",
    "\n",
    "    labels = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    token_ids = torch.cat(token_ids_list)\n",
    "\n",
    "    return labels.to(device), token_ids.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use collate_batch to generate the dataloader\n",
    "train_iter = SST2(split=\"train\")\n",
    "dataloader = DataLoader(\n",
    "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 label: tensor([0, 0, 1, 0, 0, 0, 1, 1])\n",
      "batch 0 text: tensor([ 4579,    92, 13266,    38,     1,  7742, 10000,  2927,    58,   327,\n",
      "            2,    88,  1995,   548,    11,  1791,    18,    54,     4,  6088,\n",
      "           95,   184,   262,    36,   176,   624,   591,   679,  6403,     8,\n",
      "         2010,     1,   287,   701,    25,     1,   252,  5417,   551,     1,\n",
      "          357,   116,  4856,    53,    11,     7,     9,   171,    50,   780,\n",
      "            8,  1840,   120,   952,  1037,  2723,    11,     1,   107,     5,\n",
      "          120,   161,  3473,    14,  7011,  1444,    65,   149,   414,    49,\n",
      "            3,   394,     2,   529,    17,    15,    16,   205,  3149,     6,\n",
      "            5,  7100])\n",
      "batch 0 offsets: tensor([ 0,  7, 14, 26, 34, 44, 55, 80])\n",
      "Number of tokens:  82\n",
      "Number of examples in one batch:  8\n",
      "Example 1:  tensor([ 4579,    92, 13266,    38,     1,  7742, 10000])\n",
      "Example 8:  tensor([   5, 7100])\n"
     ]
    }
   ],
   "source": [
    "# Test the dataloader\n",
    "for i, (labels, token_ids, offsets) in enumerate(dataloader):\n",
    "    print(f\"batch {i} label: {labels}\")\n",
    "    print(f\"batch {i} text: {token_ids}\")\n",
    "    print(f\"batch {i} offsets: {offsets}\")\n",
    "    if i == 0:\n",
    "        break\n",
    "\n",
    "# What does offsets mean?\n",
    "print('Number of tokens: ', token_ids.size(0))\n",
    "print('Number of examples in one batch: ', labels.size(0))\n",
    "print('Example 1: ', token_ids[offsets[0]:offsets[1]])\n",
    "print('Example 8: ', token_ids[offsets[7]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, token_ids, offsets):\n",
    "        embedded = self.embedding(token_ids, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "train_iter = iter(SST2(split='train'))\n",
    "num_class = len(set([label for (_, label) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64 # embedding size\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([8, 2])\n",
      "output: tensor([[-0.0107, -0.0334],\n",
      "        [-0.4063, -0.0219],\n",
      "        [ 0.0674,  0.1346],\n",
      "        [-0.0334,  0.2256],\n",
      "        [-0.2274,  0.0812],\n",
      "        [-0.1080, -0.3154],\n",
      "        [ 0.0026,  0.2916],\n",
      "        [-0.4137, -0.0761]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py39/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:248: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (labels, token_ids, offsets) in enumerate(dataloader):\n",
    "        output = model(token_ids, offsets)\n",
    "        # print(f\"batch {i} output: {output}\")\n",
    "        if i == 0:\n",
    "            break\n",
    "\n",
    "# Examine the output\n",
    "print('output size:', output.size())\n",
    "print('output:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Functions\n",
    "Define train() and evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, epoch: int):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (labels, token_ids, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(token_ids, offsets)\n",
    "        try:\n",
    "            loss = criterion(output, labels)\n",
    "        except Exception:\n",
    "            print('Error in loss calculation')\n",
    "            print('output: ', output.size())\n",
    "            print('labels: ', labels.size())\n",
    "            # print('token_ids: ', token_ids)\n",
    "            # print('offsets: ', offsets)\n",
    "            raise\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += (output.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, label)\n",
    "            total_acc += (output.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters, loss, optimizer, and learning-rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 8  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `criterion`, i.e., the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7035)\n",
      "loss non-reduced: tensor([0.6819, 0.9037, 0.6601, 0.8310, 0.8593, 0.5948, 0.5590, 0.5385])\n",
      "mean of loss non-reduced: tensor(0.7035)\n",
      "loss manually computed: tensor(0.6819)\n"
     ]
    }
   ],
   "source": [
    "# First, obtain some output and labels\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (labels, token_ids, offsets) in enumerate(dataloader):\n",
    "        output = model(token_ids, offsets)\n",
    "        # print(f\"batch {i} output: {output}\")\n",
    "        if i == 0:\n",
    "            break\n",
    "\n",
    "loss = criterion(output, labels)\n",
    "print('loss:', loss)\n",
    "\n",
    "criterion2 = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "loss2 = criterion2(output, labels)\n",
    "print('loss non-reduced:', loss2)\n",
    "print('mean of loss non-reduced:', torch.mean(loss2))\n",
    "\n",
    "# Manually calculate the loss\n",
    "probs = torch.exp(output[0,:]) / torch.exp(output[0,:]).sum()\n",
    "loss3 = -torch.log(probs[labels[0]])\n",
    "print('loss manually computed:', loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train, valid, and test data\n",
    "train_iter = SST2(split=\"train\")\n",
    "test_iter = SST2(split=\"test\")\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 7998 batches | accuracy    0.588\n",
      "| epoch   1 |  1000/ 7998 batches | accuracy    0.665\n",
      "| epoch   1 |  1500/ 7998 batches | accuracy    0.712\n",
      "| epoch   1 |  2000/ 7998 batches | accuracy    0.750\n",
      "| epoch   1 |  2500/ 7998 batches | accuracy    0.773\n",
      "| epoch   1 |  3000/ 7998 batches | accuracy    0.777\n",
      "| epoch   1 |  3500/ 7998 batches | accuracy    0.789\n",
      "| epoch   1 |  4000/ 7998 batches | accuracy    0.795\n",
      "| epoch   1 |  4500/ 7998 batches | accuracy    0.819\n",
      "| epoch   1 |  5000/ 7998 batches | accuracy    0.821\n",
      "| epoch   1 |  5500/ 7998 batches | accuracy    0.826\n",
      "| epoch   1 |  6000/ 7998 batches | accuracy    0.837\n",
      "| epoch   1 |  6500/ 7998 batches | accuracy    0.848\n",
      "| epoch   1 |  7000/ 7998 batches | accuracy    0.833\n",
      "| epoch   1 |  7500/ 7998 batches | accuracy    0.843\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 15.72s | valid accuracy    0.809 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 7998 batches | accuracy    0.876\n",
      "| epoch   2 |  1000/ 7998 batches | accuracy    0.886\n",
      "| epoch   2 |  1500/ 7998 batches | accuracy    0.883\n",
      "| epoch   2 |  2000/ 7998 batches | accuracy    0.885\n",
      "| epoch   2 |  2500/ 7998 batches | accuracy    0.876\n",
      "| epoch   2 |  3000/ 7998 batches | accuracy    0.880\n",
      "| epoch   2 |  3500/ 7998 batches | accuracy    0.887\n",
      "| epoch   2 |  4000/ 7998 batches | accuracy    0.878\n",
      "| epoch   2 |  4500/ 7998 batches | accuracy    0.883\n",
      "| epoch   2 |  5000/ 7998 batches | accuracy    0.882\n",
      "| epoch   2 |  5500/ 7998 batches | accuracy    0.886\n",
      "| epoch   2 |  6000/ 7998 batches | accuracy    0.881\n",
      "| epoch   2 |  6500/ 7998 batches | accuracy    0.890\n",
      "| epoch   2 |  7000/ 7998 batches | accuracy    0.880\n",
      "| epoch   2 |  7500/ 7998 batches | accuracy    0.879\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 16.88s | valid accuracy    0.873 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 7998 batches | accuracy    0.916\n",
      "| epoch   3 |  1000/ 7998 batches | accuracy    0.910\n",
      "| epoch   3 |  1500/ 7998 batches | accuracy    0.903\n",
      "| epoch   3 |  2000/ 7998 batches | accuracy    0.893\n",
      "| epoch   3 |  2500/ 7998 batches | accuracy    0.910\n",
      "| epoch   3 |  3000/ 7998 batches | accuracy    0.907\n",
      "| epoch   3 |  3500/ 7998 batches | accuracy    0.899\n",
      "| epoch   3 |  4000/ 7998 batches | accuracy    0.903\n",
      "| epoch   3 |  4500/ 7998 batches | accuracy    0.902\n",
      "| epoch   3 |  5000/ 7998 batches | accuracy    0.899\n",
      "| epoch   3 |  5500/ 7998 batches | accuracy    0.906\n",
      "| epoch   3 |  6000/ 7998 batches | accuracy    0.911\n",
      "| epoch   3 |  6500/ 7998 batches | accuracy    0.899\n",
      "| epoch   3 |  7000/ 7998 batches | accuracy    0.905\n",
      "| epoch   3 |  7500/ 7998 batches | accuracy    0.902\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 18.35s | valid accuracy    0.892 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 7998 batches | accuracy    0.916\n",
      "| epoch   4 |  1000/ 7998 batches | accuracy    0.918\n",
      "| epoch   4 |  1500/ 7998 batches | accuracy    0.920\n",
      "| epoch   4 |  2000/ 7998 batches | accuracy    0.919\n",
      "| epoch   4 |  2500/ 7998 batches | accuracy    0.916\n",
      "| epoch   4 |  3000/ 7998 batches | accuracy    0.913\n",
      "| epoch   4 |  3500/ 7998 batches | accuracy    0.914\n",
      "| epoch   4 |  4000/ 7998 batches | accuracy    0.923\n",
      "| epoch   4 |  4500/ 7998 batches | accuracy    0.910\n",
      "| epoch   4 |  5000/ 7998 batches | accuracy    0.923\n",
      "| epoch   4 |  5500/ 7998 batches | accuracy    0.915\n",
      "| epoch   4 |  6000/ 7998 batches | accuracy    0.911\n",
      "| epoch   4 |  6500/ 7998 batches | accuracy    0.910\n",
      "| epoch   4 |  7000/ 7998 batches | accuracy    0.911\n",
      "| epoch   4 |  7500/ 7998 batches | accuracy    0.911\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 22.50s | valid accuracy    0.895 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 7998 batches | accuracy    0.926\n",
      "| epoch   5 |  1000/ 7998 batches | accuracy    0.926\n",
      "| epoch   5 |  1500/ 7998 batches | accuracy    0.924\n",
      "| epoch   5 |  2000/ 7998 batches | accuracy    0.930\n",
      "| epoch   5 |  2500/ 7998 batches | accuracy    0.926\n",
      "| epoch   5 |  3000/ 7998 batches | accuracy    0.923\n",
      "| epoch   5 |  3500/ 7998 batches | accuracy    0.921\n",
      "| epoch   5 |  4000/ 7998 batches | accuracy    0.920\n",
      "| epoch   5 |  4500/ 7998 batches | accuracy    0.915\n",
      "| epoch   5 |  5000/ 7998 batches | accuracy    0.925\n",
      "| epoch   5 |  5500/ 7998 batches | accuracy    0.915\n",
      "| epoch   5 |  6000/ 7998 batches | accuracy    0.920\n",
      "| epoch   5 |  6500/ 7998 batches | accuracy    0.921\n",
      "| epoch   5 |  7000/ 7998 batches | accuracy    0.920\n",
      "| epoch   5 |  7500/ 7998 batches | accuracy    0.917\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 18.88s | valid accuracy    0.885 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 7998 batches | accuracy    0.936\n",
      "| epoch   6 |  1000/ 7998 batches | accuracy    0.942\n",
      "| epoch   6 |  1500/ 7998 batches | accuracy    0.941\n",
      "| epoch   6 |  2000/ 7998 batches | accuracy    0.943\n",
      "| epoch   6 |  2500/ 7998 batches | accuracy    0.947\n",
      "| epoch   6 |  3000/ 7998 batches | accuracy    0.950\n",
      "| epoch   6 |  3500/ 7998 batches | accuracy    0.947\n",
      "| epoch   6 |  4000/ 7998 batches | accuracy    0.947\n",
      "| epoch   6 |  4500/ 7998 batches | accuracy    0.941\n",
      "| epoch   6 |  5000/ 7998 batches | accuracy    0.952\n",
      "| epoch   6 |  5500/ 7998 batches | accuracy    0.940\n",
      "| epoch   6 |  6000/ 7998 batches | accuracy    0.944\n",
      "| epoch   6 |  6500/ 7998 batches | accuracy    0.941\n",
      "| epoch   6 |  7000/ 7998 batches | accuracy    0.945\n",
      "| epoch   6 |  7500/ 7998 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 17.08s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 7998 batches | accuracy    0.952\n",
      "| epoch   7 |  1000/ 7998 batches | accuracy    0.948\n",
      "| epoch   7 |  1500/ 7998 batches | accuracy    0.950\n",
      "| epoch   7 |  2000/ 7998 batches | accuracy    0.944\n",
      "| epoch   7 |  2500/ 7998 batches | accuracy    0.947\n",
      "| epoch   7 |  3000/ 7998 batches | accuracy    0.948\n",
      "| epoch   7 |  3500/ 7998 batches | accuracy    0.943\n",
      "| epoch   7 |  4000/ 7998 batches | accuracy    0.956\n",
      "| epoch   7 |  4500/ 7998 batches | accuracy    0.949\n",
      "| epoch   7 |  5000/ 7998 batches | accuracy    0.947\n",
      "| epoch   7 |  5500/ 7998 batches | accuracy    0.944\n",
      "| epoch   7 |  6000/ 7998 batches | accuracy    0.952\n",
      "| epoch   7 |  6500/ 7998 batches | accuracy    0.948\n",
      "| epoch   7 |  7000/ 7998 batches | accuracy    0.945\n",
      "| epoch   7 |  7500/ 7998 batches | accuracy    0.948\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 16.15s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 7998 batches | accuracy    0.951\n",
      "| epoch   8 |  1000/ 7998 batches | accuracy    0.952\n",
      "| epoch   8 |  1500/ 7998 batches | accuracy    0.964\n",
      "| epoch   8 |  2000/ 7998 batches | accuracy    0.947\n",
      "| epoch   8 |  2500/ 7998 batches | accuracy    0.946\n",
      "| epoch   8 |  3000/ 7998 batches | accuracy    0.952\n",
      "| epoch   8 |  3500/ 7998 batches | accuracy    0.952\n",
      "| epoch   8 |  4000/ 7998 batches | accuracy    0.950\n",
      "| epoch   8 |  4500/ 7998 batches | accuracy    0.948\n",
      "| epoch   8 |  5000/ 7998 batches | accuracy    0.946\n",
      "| epoch   8 |  5500/ 7998 batches | accuracy    0.948\n",
      "| epoch   8 |  6000/ 7998 batches | accuracy    0.954\n",
      "| epoch   8 |  6500/ 7998 batches | accuracy    0.953\n",
      "| epoch   8 |  7000/ 7998 batches | accuracy    0.946\n",
      "| epoch   8 |  7500/ 7998 batches | accuracy    0.947\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 15.50s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 7998 batches | accuracy    0.951\n",
      "| epoch   9 |  1000/ 7998 batches | accuracy    0.956\n",
      "| epoch   9 |  1500/ 7998 batches | accuracy    0.952\n",
      "| epoch   9 |  2000/ 7998 batches | accuracy    0.950\n",
      "| epoch   9 |  2500/ 7998 batches | accuracy    0.955\n",
      "| epoch   9 |  3000/ 7998 batches | accuracy    0.950\n",
      "| epoch   9 |  3500/ 7998 batches | accuracy    0.945\n",
      "| epoch   9 |  4000/ 7998 batches | accuracy    0.949\n",
      "| epoch   9 |  4500/ 7998 batches | accuracy    0.951\n",
      "| epoch   9 |  5000/ 7998 batches | accuracy    0.945\n",
      "| epoch   9 |  5500/ 7998 batches | accuracy    0.951\n",
      "| epoch   9 |  6000/ 7998 batches | accuracy    0.952\n",
      "| epoch   9 |  6500/ 7998 batches | accuracy    0.952\n",
      "| epoch   9 |  7000/ 7998 batches | accuracy    0.950\n",
      "| epoch   9 |  7500/ 7998 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 14.78s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 7998 batches | accuracy    0.949\n",
      "| epoch  10 |  1000/ 7998 batches | accuracy    0.952\n",
      "| epoch  10 |  1500/ 7998 batches | accuracy    0.949\n",
      "| epoch  10 |  2000/ 7998 batches | accuracy    0.953\n",
      "| epoch  10 |  2500/ 7998 batches | accuracy    0.951\n",
      "| epoch  10 |  3000/ 7998 batches | accuracy    0.949\n",
      "| epoch  10 |  3500/ 7998 batches | accuracy    0.954\n",
      "| epoch  10 |  4000/ 7998 batches | accuracy    0.946\n",
      "| epoch  10 |  4500/ 7998 batches | accuracy    0.949\n",
      "| epoch  10 |  5000/ 7998 batches | accuracy    0.942\n",
      "| epoch  10 |  5500/ 7998 batches | accuracy    0.961\n",
      "| epoch  10 |  6000/ 7998 batches | accuracy    0.953\n",
      "| epoch  10 |  6500/ 7998 batches | accuracy    0.949\n",
      "| epoch  10 |  7000/ 7998 batches | accuracy    0.953\n",
      "| epoch  10 |  7500/ 7998 batches | accuracy    0.958\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 15.58s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "total_accu = None\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train(model, train_dataloader, optimizer, criterion, epoch)\n",
    "    accu_val = evaluate(model, valid_dataloader, criterion)\n",
    "\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"text_classification_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with Test Data\n",
    "\n",
    "This is a necessary step. But since the `test` split of SST2 is not annotated, we will use the `dev` split here to pretend it is the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.904\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(model, valid_dataloader, criterion)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Test the model with a few unannotated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels = ['negative', 'positive']\n",
    "\n",
    "def predict(text, model, vocab, tokenizer, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(vocab(tokenizer(text)), device=device)\n",
    "        output = model(text, torch.tensor([0], device=device))\n",
    "        return labels[output.argmax(1).item()]\n",
    "\n",
    "ex_text_str = \"A very well-made, funny and entertaining picture.\"\n",
    "print(\"This is a %s sentiment.\" % (predict(ex_text_str, model, vocab, tokenizer, sentiment_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
